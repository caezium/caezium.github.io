---
title: "Video Conferencing, Web Conferencing, Webinars, Screen Sharing"
source: "https://stanford.zoom.us/rec/play/q5C9QfRMdlsYsUj7VoGOHokWDXgDBEeiNFy2VaMOO42KpG4LQtje6ZGS6RHYDu--Xc-1mkShLOnRiiM.BiDHFsIDPm0i-ars?eagerLoadZvaPages=&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2Fqh9oeWIwYtM8ovc8m7bKViysmHvPjtbbxjnctAl_5oucXRJxV59POK10EtU5Yjk.pQSRZ4pJTpRlKEiP"
author:
  - "[[Zoom]]"
published:
created: 2025-07-04
description: "Zoom is the leader in modern enterprise video communications, with an easy, reliable cloud platform for video and audio conferencing, chat, and webinars across mobile, desktop, and room systems. Zoom Rooms is the original software-based conference room solution used around the world in board, conference, huddle, and training rooms, as well as executive offices and classrooms. Founded in 2011, Zoom helps businesses and organizations bring their teams together in a frictionless environment to get more done. Zoom is a publicly traded company headquartered in San Jose, CA."
tags:
  - "clippings"
---
## Summary
The faculty talk introduces generative AI agents as a novel approach to simulating human behavior and societies. It highlights the limitations of traditional, rigid models and proposes leveraging large language models (LLMs) to create more dynamic and high-fidelity agents. The speaker details an architecture enabling agents to remember, plan, and reflect, demonstrated within a virtual world called Smallville. The talk then shifts to a more recent work focusing on creating accurate \\"digital twins\\" of real individuals through extensive, semi-structured interviews. These agents are validated by their ability to predict the attitudes and behaviors of their human counterparts. The presentation concludes with a discussion on critical ethical considerations, such as privacy and autonomy, and outlines future applications of generative agents in social science, policy design, and machine learning systems that can better reflect diverse societal values.

## Key Points
- **Problem:** Traditional human behavior models are rigid, limiting generalizability in simulations.
- **Opportunity:** Large Language Models (LLMs) offer a path to create high-fidelity, general-purpose computational agents.
- **Key Challenges:** Achieving long-term behavioral coherence (memory, planning, reflection) and ensuring simulation accuracy.
- **Generative Agent Architecture:**
    - Uses a \\"memory stream\\" (biased by recency, importance, relevance) to store perceptions.
    - Employs hierarchical planning (top-down, multi-granularity).
    - Integrates \\"reflections\\" for higher-level self-understanding and synthesis of memories.
    - Demonstrated believability in a multi-agent social simulation (Smallville).
- **Generative Agent Simulations of 1,000 People (Digital Twins):**
    - Focuses on *accurate* simulation of real individuals, not just believability.
    - Methodology: Conducted 2-hour voice-to-voice semi-structured interviews with 1,052 US participants using an AI interviewer to populate agent memories.
    - Validation: Measured \\"normalized accuracy\\" by comparing agent predictions to human responses on surveys and A/B tests, showing interview data significantly improves accuracy.
    - Result: Creation of the first \\"Agent Bank\\" of diverse generative agents.
- **Ethical Considerations:** Emphasizes privacy, autonomy, IRB oversight, continuous auditing, and the right to withdraw consent.
- **Future Applications:** Envisions AI agents as a scientific method for societal decision-making, aiding in the design of social computing systems (e.g., Subreddits) and developing machine learning systems that incorporate diverse human values (e.g., \\"Jury Learning\\").

---

https://stanford.zoom.us/rec/play/q5C9QfRMdlsYsUj7VoGOHokWDXgDBEeiNFy2VaMOO42KpG4LQtje6ZGS6RHYDu--Xc-1mkShLOnRiiM.BiDHFsIDPm0i-ars?eagerLoadZvaPages=&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2Fqh9oeWIwYtM8ovc8m7bKViysmHvPjtbbxjnctAl_5oucXRJxV59POK10EtU5Yjk.pQSRZ4pJTpRlKEiP
# Original Content

[Accessibility Overview](https://stanford.zoom.us/en/accessibility)

<video src="https://ssrweb.zoom.us/replay02/2025/06/26/E9750A0B-F06E-4CB4-B052-12C705A2A356/GMT20250626-194153_Recording_1920x1118.mp4?response-content-type=video%2Fmp4&amp;response-cache-control=max-age%3D0%2Cs-maxage%3D86400&amp;data=ba89b7a4df6f0b14f6c49cce8fafe06ecf7a69d8d0c89f91def92d21f26953e0&amp;s001=yes&amp;cid=aw1&amp;fid=1Xi6zdclRtBJBi-upeVCrKU35ddrbe7k6LizQFAWXfOi67eccv-lzqfgr3xdgXScw3xzo2WAdpUiPJc.kcQj8LhV9VUJ7GlF&amp;s002=YZFL-CazSSRi2LvkhK0MUpFz2yQyy5W5jU_bLSApGc5ZJG1qv3ArZmNpXk5ve05UsIBxgq4CA_4gItOUg_esmTSpkTjH.q3ZQhu1UdmjiLWuL&amp;tid=v=2.0;clid=aw1;rid=WEB_d6f6571d1d9253bdd83de328ca20b803&amp;Policy=eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6Imh0dHBzOi8vc3Nyd2ViLnpvb20udXMvcmVwbGF5MDIvMjAyNS8wNi8yNi9FOTc1MEEwQi1GMDZFLTRDQjQtQjA1Mi0xMkM3MDVBMkEzNTYvR01UMjAyNTA2MjYtMTk0MTUzX1JlY29yZGluZ18xOTIweDExMTgubXA0P3Jlc3BvbnNlLWNvbnRlbnQtdHlwZT12aWRlbyUyRm1wNCZyZXNwb25zZS1jYWNoZS1jb250cm9sPW1heC1hZ2UlM0QwJTJDcy1tYXhhZ2UlM0Q4NjQwMCZkYXRhPWJhODliN2E0ZGY2ZjBiMTRmNmM0OWNjZThmYWZlMDZlY2Y3YTY5ZDhkMGM4OWY5MWRlZjkyZDIxZjI2OTUzZTAmczAwMT15ZXMmY2lkPWF3MSZmaWQ9MVhpNnpkY2xSdEJKQmktdXBlVkNyS1UzNWRkcmJlN2s2TGl6UUZBV1hmT2k2N2VjY3YtbHpxZmdyM3hkZ1hTY3czeHpvMldBZHBVaVBKYy5rY1FqOExoVjlWVUo3R2xGJnMwMDI9WVpGTC1DYXpTU1JpMkx2a2hLME1VcEZ6MnlReXk1VzVqVV9iTFNBcEdjNVpKRzFxdjNBclptTnBYazV2ZTA1VXNJQnhncTRDQV80Z0l0T1VnX2VzbVRTcGtUakgucTNaUWh1MVVkbWppTFd1TCZ0aWQ9dj0yLjA7Y2xpZD1hdzE7cmlkPVdFQl9kNmY2NTcxZDFkOTI1M2JkZDgzZGUzMjhjYTIwYjgwMyIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTY0Mzg0MX19fV19&amp;Signature=XkhjKyv~MCfYKkiVeLnmSd1L6O83cPvx-Tbp585WHb1m3nLOaJlGTPfQH4qqdUrhsuT1zGXqgoyPb-p3L08m39Y0okyLyCnsJ6-tAFE8mWpN4sIZCBUhALLo2Fq-xAFuPxx52uZWrIg8GP5N-ABuMTHXhcK7zmMjL5ZzSyMElMneIVBlRzS5AZlzaHpQaqTO1XKHV8WD61ueoAHjXcqlU46rve9urchBmRsBI4NDuHWuNfgyON9~otC2QRWbRAWuSP6lvUGjwht~EJTWih6vBi9~DhlhZM2wAyHTvn3p7gqVjwXbK1BrTZJakv4Wcsgr~LP9PJASnX1IarigNHPPeg__&amp;Key-Pair-Id=APKAJFHNSLHYCGFYQGIA"></video>

00:00:00 / 00:59:04

## Audio Transcript

## Chat Messages

- 00:04
	It's
- I'm not sure if anyone's been in coda or at least folks from High may have been to coda. It's getting a room to give talks, and has gotten very competitive. So apologies that I sort of am moving the location here a little bit. Yeah, but really nice meeting. Everyone is everyone sort of and just so I know the audience. Everyone's joining. And you're sort of all in high school and stuff like that right now. Is that right?
- 00:28
	Yep.
- 00:30
	Exciting, all right. Well, I'm excited to talk to you all arising sophomores. Yes.
- 00:35
	Fantastic. So it seems like we have a bit of a range.
- 00:39
	So I'm excited to talk to you. And I thank you so much, Mariam, for the really wonderful introduction. Yeah, excited to talk to you all about agents and generative AI, and so forth. So I would love to sort of make this as interactive as you all want this to be. So feel free to stop me whenever. But
- just to make sure that you all can see the talk.
- Okay, if I do this, what can you see? Can you see the the slides.
- 01:11
	Yes.
- 01:12
- Okay? So I give that I sort of start to talk. But yeah, feel free to stop me. If you have any questions, feel free to just shout in the chat, let me just make sure that the chat window is open, so I can see what everyone's typing.
- Great rising software is from all over the world. I love it cool.
- So Hi, everyone again. My name is June. Maybe there's a small update in my status. I have officially graduated. So thank you. Thank you. So now I guess I feel older than even I used to be. But I guess that's just that's the context. But yeah, it's really excited to be here. So I got my Phd in the computer Science Department at Stanford.
- And 2 show you that we've now reached a meaningful starting point for developing high fidelity, simulations of individuals and societies that bring us closer to realizing these visions.
- Okay?
- And I want to start our conversation here.
- So what you're seeing here is a grid world with red and blue squares, you might think of it as representing a hypothetical mixed neighborhood of red and blue.
- Now these squares, or agents, as we might call them, are perfectly happy living in a mixed neighborhood, or even in a community where they're the minority.
- Their only real preference is that they don't want to be a significant minority.
- So concretely they want to live in a location where at least 30% of their neighbors are of the same color as them, and if this condition isn't met they'll simply move to the closest location that is acceptable.
- But here's a catch.
- Despite a very weak preference, this collective process will lead to the emergence of a clear segregation. As you see here.
- This is Thomas Schelling's Nobel Prize-winning work on agent-based models. Specifically his 1971 model of segregation, and this simulation of it's a simple, highly stylized one, challenged our assumption.
- But this simulation showed that every weak, even very weak, preferences to be near people similar to you is sufficient to produce aggregation. And in the years that followed this simulation inspired policies like inclusive zoning and mixed income housing that are still, in effect, today.
- are built on assumptions about human behavior, and sometimes those assumptions are misguided
- simulations, if designed right, I want to argue, can help us challenge those assumptions and push us to ask what-if counterfactuals to imagine different explanations and solutions for the problems facing individuals and societies.
- They depend on countless idiosyncratic factors of the individuals and the environment. But the models of human behavior we had in previous decades were rigid.
- They were defined by just a few highly stylized parameters, oversimplifying and restricting agents to specific domains, and this made the pictures painted by these simulations hard to generalize.
- So I posit that with the right method they can be transformed into the core ingredient that have been missing in the past decades to create general purpose, computational agents that are capable of powering complex high fidelity simulations.
- But there are 2 main challenges that we had to overcome for that to be possible.
- One is that of long-term coherence. People live for many decades, and we can constantly see and make sense of things.
- but testing a large language model to reason over all that experience, for every single decision is not only extremely inefficient, it's also right now simply not possible.
- So even with the expanding context window of these models, we might at most fit a day or 2 worth of detailed experiences.
- So the question is, how can we augment the language model to empower agents that remember, reflect, and plan based on their experiences.
- And then there is the question of accuracy for these simulations to truly inform important decisions. They need to be not just, believable.
- but accurate. Creating agents that are accurate requires a foundation and ground truth, and for individual agents that ground. Truth ought to come from real individuals. But what's the right method for creating agents that can represent a diverse group of real individuals and validate them?
- If you simply give a length, model my demographic information and my status as a graduate student.
- or now a graduate of the graduate program, something like a 30 year old Asian graduate student in computer science, and it produces descriptions like June will be in his office writing a paper on Monday morning. It writes for lunch and stay indoors all day. Is this accurate, or is that just a broad, stereotypical generalizations?
- So today I'm going to show you how we can overcome these challenges and demonstrate that we can now, indeed create general computational agents, that leverage generative AI models like Chatgpt
- to accurately simulate the attitudes and behaviors of individuals across a wide range of context.
- These agents, I'll demonstrate.
- can not only plan and lead a believable day in life where they wake up in the morning, do their routines and go to work as individuals as in a sandbox game environment with no hard-coded scripts.
- but they can also come together to give birth to an entirely artificial society of their own, like this.
- Okay.
- so and so, this is actually the demo that we actually have created as a part of this research. So I don't know how many of you actually played like games like the Sims pokemon all these kind of games.
- And so it might be very reminiscent of those kind of platforms. So we actually create a game. So this is actually what you get to do. If you're a researcher in this space, you get to create games. But except Npcs are now live, and they talk to each other and have relationships. And we name these generative agents
- and these generative agents. I'm going to suggest open up new opportunities in the way we understand individuals and our societies.
- Okay.
- so that's sort of the work that we do in the lab, and basically go over a couple of papers in this space.
- honestly, like, you know, and depending on sort of where all of your interest is, I'm happy to focus on one or the other, and so forth. And so yeah, feel free to just jump in and ask questions or stop me as I go. But otherwise, for the rest of today's talk, I basically show you
- how you can create digital friends that live in Sims basically and try to convince you that that is actually a useful research question. For for, like graduate student like myself to pursue.
- Okay, so
- I'm going to orient my talk around 2 of the works that I built during my Phd. The 1st is called generative Agents, interactive simulacra of human behavior. In this work I present what is one of the very 1st agent architectures in the field to basically leverage the Lors Lynch model for creating agents and demonstrate that these agents can generate believable behaviors for fictional characters.
- Then, in our latest work, generative agent simulations of 1,000 people, I'll demonstrate how we can extend this generative agent architecture to accurately model a real representative sample of American individuals.
- So let me start with generative agents. This is work that was published at Wist in 2023,
- and in this portion of the talk the plan is to work up to the generative agent architecture that you see here, which I'm going to show is necessary for creating compelling agent behavior.
- But before I do, I do want to 1st show you what it can do.
- so let me officially welcome you to Smallville. What you see here is a map of a game world called Smallville.
- that we developed to grant the behaviors and interactions of our agents.
- and we populated this space with 25 generative agents, each with distinct identities that we've given them described in one paragraph of English sentences.
- For instance, we told Isabella that she is the owner of Hubs Cafe, who loves to make people out, loves to make people feel welcome, and that she is planning to organize a Valentine's Day party.
- and with that as the only human input we aim to simulate behaviors for these agents.
- For instance, here's what Isabella's typical day looks like. In broad strokes she wakes up early and completes her morning routine around 6 A. M. And she prepares to open the cafe by 8.
- She notices and interacts with her customers throughout the day, perhaps even inviting them to the party that she is planning. And around 6 Pm. Her working day ends with her going to a local store to buy supplies.
- and in close-up we can see that these broad stroke behaviors are composed of smaller sequences of actions that impact and alter the game world environment.
- If, for instance, Isabella outputted a high-level behavior to make and drink coffee.
- she would 1st clean her cup, then change the status of the coffee machine to be turned on and occupy one of the empty chairs in her cafe as she waits for her coffee to finish brewing.
- So take a look at this interaction between Latoya and Sam, for instance. So this is actually the conversation they had throughout the day. Right? So they met at this park, and at the start of the simulation, wanting to notice that these 2 do not have any prior information about each other.
- So the 1st time they meet is while taking a walk in a park. They introduce themselves, and Latiya tells Sam that she is taking photos for a project that she's working on.
- And the next day, when Sam sees Latoya again, he remembers her as well as her project, and asks, How's your project going? To which Latoya responds, Hi, Sam, it's going well.
- but that's not all. In Smallville. You do not have to be a mere passive observer of these generative agents. Instead, you can interact with them. You can change their environment. You can burn their toast and watch them, to rush, to put out the fire and remake their breakfast like you see here, for this is Wolfka. So he woke up in the morning. He was making toast, and he decided to burn it or put it on fire. So you're basically seeing him cleaning up, you can sort of see the small emojis to show what he's actually up to.
- or commend the agents by rewriting their memories to plant new ideas like here, where we told John that he's now running for an office.
- So how do we achieve this agent behavior?
- What makes gender loop agents possible today is the development of large language models. But, as I pointed out earlier, these models with prompting alone have pretty dramatic limitations.
- And that's what generative agent architecture is. And here's how this works.
- First, st we translate the perceptual stimuli of an agent into natural language sentences. For instance, if in the case of what Isabella perceives at her cafe, it's phrases like Maria is chatting with Klaus, or the chair is empty, and so forth.
- Then we store these sentences in their natural language format in a long-term memory module that we call the memory stream. So what you see here is the tip of Isabella's memory stream. In practice this is a very lengthy document.
- but now the challenge here is that this memory stream is too large to efficiently fit into the context window of a large language model, and even if you could feeding the entire memory stream would distract the model and make it terribly inefficient.
- So we retrieve from it only a small subset of the memories that are most relevant to responding to the agent's current situation.
- So when Isabella is asked, What are you excited about? She might retrieve memories that are about her Valentine's Day party.
- Here's how we designed this system. So in our architecture. We designed it as a combination of recency, importance, and relevance function for each piece of memory.
- So basically, we bias towards retrieving memories that are more recent, important and relevant
- in our work. The recency function is implemented as an exponential decay function, and the importance function is a prompt that asks the link model for an event saliency and the relevance function is a cosine similarity measure of the embeddings of the current context and the description of a memory.
- We then use the retrieved memories to generate plans and reflections, using the language model which are then translated into the concrete actions that you see in the environment.
- Now let me dive deeper into the planning and reflection modules here, since these are the core modules for generating agent behaviors.
- So 1st planning.
- planning, and planning and agents has been around for a long time, especially in robotics and so forth. So here we're not necessarily trying to say this is the best thing one could ever possibly do. But just to demonstrate that we can now do it this way.
- and planning from generative agents is quite useful, because without it. The language model is quite prone to optimizing for believability in the moment at the cost of believability over time.
- So a very simple example in this of this failure is an agent deciding to eat lunch at 1130, which is reasonable, but then deciding to eat lunch again at noon, and again at 1230, because any of those times are reasonable time for lunch
- in our work. We generate the plans by prompting a link model with a prompt that summarizes the agent and the agent's current status, as you see here for Eddie.
- Okay.
- now, a challenge here is controlling for the granularity of the plans that are getting generated in our work. We address this by taking a top-down approach where we recursively generate more plans and more details in the plan.
- So here's an example. On the left-hand side is Eddie's plan, generated in broad strokes, dividing his day into roughly 7 chunks.
- We then decompose these trunks, 1st into an hourly schedule, and then into 5 to 15 min actions, as you see on the right hand side.
- Once we've reached the desired granularity, which is in our case, one action every 10 seconds or so of the game time. They act out their plans in the game world.
- but sometimes the agents may need to change their plans. For instance, if Eddie's father, John, records that he sees Eddie taking a short walk in the house garden, he might decide to start an impromptu conversation.
- And now let's talk about the reflections.
- This was a practical, interesting module for us, and here's the motivation behind it.
- Imagine you asked an agent who would you want to hang out with the most
- agents. Without this reflection, Module would retrieve all the memories about other agents, and record and respond with the one they see the most often, not the one they have the closest relationship with, but the one that who lives maybe next door in their dorm, or something like that.
- And that didn't seem quite right. So to address this, we started asking agents to retrieve specific memories and begin formulating reflections about themselves. So these are basically their shower thoughts.
- So over time, these agents start to generate these trees of reflections. The leaf nodes are basically the observations, and the non-leaf nodes are thoughts that become higher level higher up the tree. They are. So here's 1 for Klaus.
- So you actually see at the very bottom, like the raw observation he made about himself right? He is reading about gentrification and urban design.
- But then that gets mapped onto a thought or sort of a synthesis of those observations. Right? So. Oh, maybe Klaus spends a lot of time reading, and this get combined into another sort of set of reflections and observations, and at the very top you start to see something that's much more fundamental about Klaus that defines who he is right. Or maybe he's highly dedicated to research.
- So is this agent architecture successful in generating human behavior.
- In this portion of my talk, I'm going to measure what we call believability of these agents, which has been a long-term research and engineering goal in our field.
- Especially do these agents exhibit behaviors that are plausible.
- Now I do want to put a highlight on this concept of believability, though, because in the next portion of my talk I'll demonstrate that we can design these agents. So their behaviors are not only believable, but also measurably accurate.
- But for now, to evaluate the agent's believability, we leveraged a methodological opportunity by interviewing them in natural language.
- so to respond believably, the agents must successfully retrieve and make sense of their memories.
- We then task our agents, a generative agent, architecture along with a bunch of ablated architectures and human crowd workers role playing as these agents to answer the questions. And when I say ablated architectures for those of you who's not familiar with the term
- that basically means on the architecture might have a different component. You're turning off each component one by one. So you know which component matters the most right? So that's how I so. Basically oh, what if we make the agent unable to remember, unable to reflect, and unable to plan all those kind of things?
- And what we find is that the generative agent architectures that are generative agents that are fully equipped with the architecture that I proposed here produce behavior that is significantly more believable than both Chatgpt and other ablated architectures, and even the human crowd workers.
- and to study the emergent societal behaviors we track how Isabella's Valentine's Day party develops what we find is that over time in the simulation, Isabella invites 12 agents to the party, and even enlists Maria to help decorate the cafe, and later that day Maria in turn asks Klaus her secret crush to go to the party with her.
- Okay?
- And on the day of Valentine's, despite many potential points of failure. Right, Isabella must remember to invite others to the prairie attendees must remember the invitation. Those who remembers must decide to actually show up, and more. Our agents succeed to coordinate as we might. So 5 agents here, including Maria and Klaus, actually show up at Hobbs Cafe to enjoy the festivities, while others choose not to or to simply forget, as we sometimes do in real life.
- Okay.
- Okay.
- so the developer community and the public have really embraced this idea. Open source repo that we launched for generative agents became the fastest growing Github Repository in the entire world during its 1st week, and it helped shape many of the agenting software systems that are powered by lynch models.
- And what's been particularly exciting for me is that this has inspired some really exciting research agendas that are just starting to shape out.
- We are also seeing generative agents offering safe rehearsal spaces for students and educators in topics that are ranging from conflict resolution to other scenarios that require interactive activities.
- And we're seeing generative agents open up new ways to study interventions for societal challenges, such as systematic racism by illustrating the causal mechanisms and outcomes of policies, especially in cases where comprehensive longitudinal data is not available.
- Okay, so that was generative agents, interactive simulatra of human behavior.
- And just to summarize this work made one of the very 1st architectural contributions to creating agents using a large Lynch model.
- It demonstrated a multi-agent societal simulation.
- and we evaluated them for their believability by interviewing them.
- Now let's pause here for a second. Now actually, I do want to. So the next portion of this talk is basically me talking about like going beyond believability to basically create one. We might also even consider to be like digital twins of real people, basically accurate simulations of individuals.
- But before I do, let me actually briefly pause here and see if there's any questions in the room that I can answer. I see one question that that Audrey asked in the chat, so maybe I'll start by just answering that, and then, and then I can go on to the next portion of the talk.
- Okay? So just to quickly answer. So Audrey asked
- medical AI track for this camp and the simulation you showed about the Npcs living in and building relationship prompted me to wonder in the context of AI in medicine. Can we simulate the impact of one's environment on one's health over a prolonged period of time.
- So I think this is actually quite interesting. There's actually a lot of interesting conversations that people are having about basically medicine. So in one individual.
- the 1st question is, the 1st answer is likely, yeah, especially if these models are sort of equipped with how some of the illness might propagate one research that actually have come across my table recently
- So I believe it was this paper. So I actually had some colleagues who created. So we remember that we created this sort of game world that I just showed you. We had a colleague who basically created something like this.
- So this is a recent paper
- they're calling it infected Smallville. So they basically took our game map of Smallville that I just showed you. But it basically spread. But they basically implemented some kind of illness like Covid, and something like that
- to basically see. Oh, if there is, let's say this influenza. So I guess in this case it's h 1 n. One epidemic, how people's reaction differ and how the illness spread over time. Right?
- So that's actually some of the research that's actually going on so kind of things that people are studying is oh, right? So if there is epidemic that's going on, maybe less people will show up at this party compared to. This is, I think, what we had in our in our work, where we had more people show up at this party.
- And then, obviously, you can also do these kind of things? Where? How would people travel like? Would people still go to the market to buy supplies? If there's epidemic they might, but much less so than, let's say, when there's no threat condition. So there are some of these kind of works that's going on in this space, which I think is exciting and sort of interesting.
- Okay?
- And let's see.
- Michael also asked, were sort of the pixel art characters necessary for the experiment? Or were they just a cute artistic touch. It's a good question. I mean, what is necessary. I mean, I think fun is necessary in my view, and I think we are sort of big part. I don't know. The team is a big fan of these kind of small games, so we wanted to have fun. So it turns out that. Yes, it's okay to have fun in professional research, too.
- But it's a good question like, was it necessary? Not really, in in a way.
- right. The core capability that you're showing is that these agents can really behave and live in these kind of environments. So was the game environment necessary, like absolutely necessary. No. Now
- did the game environment. And having that visceral demo really change the way we communicated this capability to the rest of society. Yes.
- right? So one way that people in my field often sort of
- actually one really good example. Actually, this, this is actually very common to the extent that this is interesting to all of you, especially if you're thinking up down the line when you're going to, you know. Go start your college career. If you're interested in research and like computer science. And these kind of things.
- one common tactic that some of research community, like some members of my community, like to deploy
- is to basically create simulations or to basically demonstrate technology in context that people are deeply familiar with like games. So you may have seen how many of you. I don't know how easy it is to do like raise hands or something like that, but I'm guessing. Many of you have seen things like the deep minds like, you know, AI, that can play go chess. And these kind of things.
- Yes.
- yeah, I've seen and seen some thumbs up right? People have also implemented things like Starcraft agent and those kind of things.
- Now, the reason why you do that is basically to demonstrate that we can create technology that can basically play these games. Now.
- does it really matter? Is the end use case of this technology just to play those games? No, right? That's not in the end. The use case of this technology is not to have them play the games.
- but where they are really useful is, everyone plays these games. So we viscerally understand what it means, like what it takes for these agents to be able to play these kind of games. Now, the kind of like Sims like this kind of game world that's really interesting. Because
- that world basically replicates our world. Sims is basically designed after like human world. So if an agent can live in there. Then they'll really start to viscerally show to the rest of the community where the technology is that these agents can maybe actually live in this kind of world.
- And that's super exciting. So this is a really good way to demonstrate power of technology. And it has been a common tactic that many members of my community have leveraged and also sort of you know, it's again, it's also fun. I think there's actually a lot of games that actually got developed based on this paper. So a lot of game companies are now trying to implement these Npcs. Do I think of it as like the core use case of generative agents. Maybe not.
- Is that fun? Yeah, that's always good.
- Okay, let me answer a few more questions here. How does the memory, retrieval and reflection. Pipeline differ from traditional rag. It's a good question. It's very similar, right? So actually.
- the the memory architecture that you see here basically came out roughly the same time as when Reg got introduced right. So this was 1 1 of the very early works that actually introduced this kind of system of doing retrieval.
- in the sense that the kind of thing that we're trying to do is like do reflection. So it's not just about retrieving memories that are the most relevant. But we're trying to retrieve memories that are relevant to that particular person, right? Things that are memorable.
- So if you're trying to build a Google search engine, I mean, maybe that's not the best example. But right? That's what Reck often gets used for what you want to retrieve is memories that are sort of the most relevant to your current context
- here. That might not actually be the case, because sometimes we do remember, like people remember useless things right? The one breakfast that you had that like really, really sunny like in the morning, and something like that. Then.
- for whatever reason, was very memorable to you, remember those kind of things. So the goal of what you are trying to retrieve could actually differ here a little bit. Right? So that's how it differs. But philosophically very similar.
- Okay, Addison asked, what is the greatest unresolved challenge in taking generative agents from fascinating simulations to really reliable and ethically integrated real world applications.
- So this is the part that could actually be a really great segue for the sort of next portion of the talk which is to show that these are not just believable. But they're accurate simulation of human behavior. So one of the ways that we actually do get do see, these agents potentially having a really large impact
- That's a really difficult task.
- And what my colleagues in that space and this also at Stanford, we have a bunch of like political scientists are the kind of thing that they want to study is well, what kind of intervention or messaging can we put out to actually reduce that polarization? Very hard question to answer? What they do is they actually put out a bunch of interventions. What if we use this kind of strategy? What if we change the algorithm this way
- to test any one of those is very expensive and slow. So they if they have 100 different ideas, they get to test, maybe 2 or 3 right, and they run out of budget and time.
- If we can do that in simulation.
- you can basically test all 100 within the matter of a couple of hours, maybe.
- Okay, I'll maybe answer just one last question that got asked, and then just quickly go over the rest of the slides, and then I can come back to some of the questions again at the end. Do they know they're just characters in a game? Or will they realize that in the future?
- Yeah, good question, who knows? Maybe we are living in a game? So yeah, at some point we should ask these agents if they know that there are game characters. It's a fun question to ask. These agents
- is simulation theory real?
- I guess that's that's yeah, we're fine now, but cool. So let me go back to my slides quickly.
- Okay, so hopefully, you can all see my slides again.
- So the next part that I sort of want to discuss and sort of present. Here is the latest work in this space that we call the generative agent simulations of 1,000 people. And this is where we take the 1st step in answering these questions.
- So this work is a preprint. So it's still under review. But it has sort of received a lot of attention in this area. I think it's it's a really fun one to talk about.
- So in this one, what I'm going to focus on is individuals. So I'm basically going to demonstrate to you that we can now create generative agents that can simulate the attitudes and behaviors of a real diverse group of individuals. So basically, can we create. So in the previous paper, I created like these fictional Npcs. Now, I'm trying to turn one of all of you may be down the line into agents or into not Npcs, but agents that basically can be like a digital tune of who you are.
- and then to validate the agent's accuracy by and then we want to validate this agent's accuracy right? And we do that by testing them with predicting their source, individuals, attitudes, and behaviors. So that's the test.
- And here's why we want to do this.
- My underlying argument here is that the stronger, the more general the model of individuals, the more persuasive the conclusions are of those simulations.
- So how do we do this? How can we create generative agents of real individuals.
- Oop.
- Okay, here we go.
- Now.
- if you're sort of familiar with the budding literature, actually, maybe maybe this is more academic side of me talking so maybe I can be a little bit more at a high level. So you may have used things like Chatgpt or character AI, and so forth.
- You may have noticed that you can actually ask Chatgpt, hey? Pretend to be. I don't know. Input your famous like, your favorite movie character.
- Chatgpt actually will do a pretty good job right that it can pretend to be that person. It can role, play it as that person. In the similar way, you can basically ask Chatgpt
- to basically give it like, very simple, like a persona or like demographic information. Hey? So imagine you wanted to role play as me, you can say, Hey, what would a 30 year old Asian male living in Palo Alto do in this kind of context? Right? So you could do that now the problem of doing that
- is, it produces very simplified and stereotypical behaviors, which sometimes is not a bad thing, right? It's making its best guesses. So if it says, Hey, June is a graduate student in computer science, and the guy is never going to leave his office to see. You know the sun
- in some, you know, average day. That might actually be true. Right? So it's not necessarily a totally wrong thing to say. But at the same time people are very unique, and they have what we might consider to be very idiosyncratic features that might not get captured by these kind of demographic information.
- So here's my view.
- People contain myriad idiosyncratic factors that can't easily be summarized by their demographic attributes or a short persona description.
- and as much as we might hope for a clever trick to solve this. The reality is, there's no shortcut to really learning and representing these factors.
- So what I end up doing in these work is, I interview people.
- Okay.
- And that's exactly the kind of thing that we need when we are trying to learn about the lives of people and anchor the behaviors of generative agents.
- Okay.
- so let me go a little bit more in depth into how exactly we've done this in our study.
- So we actually started by recruiting human participants. So these are not agents. These are actual people. And you know, down the line. You're also welcome to be our participants and join our study. But for this study we actually partner with Bovitz, which is a recruitment firm, and we gathered a representative sample of 1,052 individuals from the Us.
- We then conducted 2 h voice-to-voice, semi-structured interviews with each participant using an interview script that was developed by our colleagues for American Voices project.
- and 2 things that are worth noting here. First, st the interview script is intentionally very broad and open-ended. So the 1st question we literally ask is something like, Tell me the story of your life.
- in the second, this interview script is completely independent from us, as well as from the surveys and experiments we are using to validate the agents.
- So this AI interviewer was designed to facilitate real-time voice-to-voice interviews with participants, and within the time limit it could also ask follow-up questions, or steer the conversation in unscripted but meaningful ways.
- So this is what it looked like. So, yeah, so this is the interviewer. So you actually see, that's actually Isabella, who used to be the cafe owner in the previous paper that you that I just presented. But now she goes around and talk to a bunch of people for 2 h is basically the idea.
- What we and what we get out of this is actually really rich qualitative information about people.
- Right?
- So here you actually see some of these
- Okay.
- then we took these interview transcripts and used them to anchor the agent's behaviors. So basically interview transcript populates the agent's memories.
- So to address this, we ask each participant to complete our battery twice 2 weeks apart.
- So what do we find?
- And we also do quite well on something like a randomized controlled trials or a B testing. These are basically studies where you basically show people a bunch of different conditions and ask them to compare those conditions. Right? Oh, imagine I got. Let's say, agents don't drink coffee. So coffee is actually not a really good idea, or it's not a best example, but gets the message across.
- How awake do you feel when you drink coffee versus not those kind of things can be a really good example of kind of like a B testing. And we predict those results quite well
- and turns out, interview really does help in bridging the gap.
- Right?
- The intuition here
- is that if you have interview data, we basically get what we might consider to be long tail information about the person.
- So some of our participants basically come back and say, Hey, I recently recovered from cancer. That's actually something that one of our participants mentioned in the interview turns out, if we know that we likely know their like financial stability, we likely know their outlook on health and well-being so ends up being very predictive of their behaviors.
- So intuition again, here is interview when you combine it with something like generative agents, is very powerful way of modeling people.
- And this is actually the 1st way that we actually have now to basically create models of not groups or populations, but of individual people to actually create like digital twins of one individual.
- And when you put together, what we basically create is basically this kind of agent bank, right? So as a part of this study. What we've created is 1,000 generative agents that represent a real diverse group of individuals, and collectively they make up the 1st Agent bank of its kind.
- and we believe that this Agent Bank provides the right foundation for building future research and simulations.
- So this is something that we work with. Irb. So Irb stands for institutional Review board. So if you ever get to do research as a part of university nowadays, all universities have their own Irb program. So they are basically experts in ethics and safety, and so forth, that work with you to basically make sure that you draft a system and sort of a proposal that can make sure that we safeguard our participants and subjects. So the kind of things that we do
- here is we basically control different access point to the agent bank. So instead of letting anyone just access this agent bank at random, right? We continuously audit these kind of system to see what kind of questions actually get asked to these agents and
- basically letting our participants then be able to pull their consent from the agent bank so they can say, Oh, I do not want my data to be represented in this agent bank anymore. Then we put their data. So those are the kind of things kind of things that we do and that we work with as a part of this research program. So maybe another way of saying it is being a researcher
- today goes beyond thinking about the scientific progress of the field, and then to almost envision, like at really the cutting edge, envisioning what the policy and what the mechanism ought to be to basically create a field that can really be beneficial and impactful for the rest of the society
- while minimizing the potential risks that the field might present right? And every technology that is powerful certainly present many kinds of risk. Right? AI has its own set of risks certainly is the case for simulation and thinking about those areas critically is one of the one of the core activities of researchers today.
- Now I do want to sort of reflect on what kind of work that you might see, as these fields sort of develop down the line.
- If we stay vigilant with safety and ethics, and so forth. I really do believe that in the coming years AI. Agents and simulations will become a distinct scientific method that really empowers to reason about societal decisions.
- And we've already seen concrete evidence that simulations can indeed support this. So just to highlight just a couple of ideas here that we worked on.
- And and then we found that giving designers the ability to simulate communities really does help them anticipate opportunities and challenges within their communities.
- For instance, they identified unexpected model citizen behaviors like impromptu franticking for sightseeing a community focused on sharing fun events around Pittsburgh, and they also uncovered unexpected, undesirable behaviors like troll farms, shifting the tone of a discussion community
- right?
- And if you can simulate individuals, you can also create machine learning systems that more closely reflect the diversity of values when making decisions on our behalf.
- So we had this project called jury learning.
- And basically, we observed that in many places where machine learning classifiers are deployed like deciding what content should be considered toxic or harmful.
- There's actually a lot of underlying disagreement within the human population about what the right decision ought to be.
- But today's machine learning systems largely ignore these disagreements, and for the most part take a majoritarian perspective by simply aggregating aggregating annotators, labels into a single label.
- But if you can model the attitudes and behaviors of individual annotators. You can instead specify juries
- that will push us to explicitly articulate what proportion of the jury should represent each group and intersectional identity.
- and in practice this process often encourages communities to recognize the voices of historically silenced minority groups. So when we applied this in a field experiment for content moderation. The communities in our study often chose to amplify the voices of minority groups that are affected by online harms.
- Right? So just to sum up today I introduce you to the concept and method of using generative AI like Chatgpt to create agents and simulate human behavior. I also showed how my work aims to build a scientific foundation for these simulations that are grounded in models of individuals.
- And I hope you're starting to see the threads that connect my work. Our lives are full of complex and important societal decisions, and this new generation of simulations, powered by generative agents gives us a powerful new tool, a new opportunity to make sense of these decisions.
- And in saying this, of course, I'm not suggesting that these simulations are perfect or that they'll ever be. But what I am saying is that there are so many problems these simulations can help us tackle. And I believe this is a research agenda that is worth pursuing.
- I do see Teresa's hand, so maybe I'll let Teresa ask a question, and then, if we have time I can circle back to some other questions in the chat as well.
- 51:56
	Thank you very much. Just a quick question. I'm just kind of curious, like how you store all the data.
- 52:03
	Right. You mean this for the generative agents.
- 52:06
	Yeah.
- 52:07
	Yeah, so surprisingly, we actually store all the data basically in a large text file, that's actually the beauty of generative AI right in the past. We actually had to encode all this data in some smart like encoding and vector embeddings. And so forth. Nowadays, we can actually store like literally like txt file and agents can act on that.
- That's what we do, obviously for doing sort of the retrieval system. We do, then transform some of this into vector embedding for those of you less familiar with that concept. That basically means you're
- you're basically turning like text into numbers, like where the vector is is how we call it to make sure the machine can urse it. But that's what we do.
- Okay?
- So maybe I can answer.
- if anyone wants to raise their hand and ask a question, happy to answer them otherwise let me see if there's any question in the text.
- Oh, Aaron.
- 53:05
	Have you ever tried simulating human evolution.
- 53:09
	It's a good question.
- So not human. So we've run simulation for about 2, 3 days. I think that's the longest simulation that we had, but I think down the line. I agree like that the much longer simulation where we let these agents literally like simulate many, many years of human existence, I think, could be really interesting.
- Some, I think researchers are actually interested in doing that right now. I do think it's scientifically. It's a little bit early to really be able to do that. But I think it's it's a path.
- Alex.
- 53:40
	Yeah, okay, I'm Alex. So you mentioned that these generative AI agents can become like more and more lifelike. So I was just wondering, like, what if people use them to like, let's say, do interviews, or to scam people. So how do you think like you can actually differentiate between an actual person and the generative AI agent.
- 54:00
	Yeah. So this is, I think, a really important question. And I also think this is where we as a society, need to have a normative position on what is acceptable and what is not.
- Now, good actors like good developers, will follow that rule. But obviously there's always the bad actors. And the question is, what do we do about them? This is where I think, at the system level that we continuously need to be auditing these systems to make sure that these agents are doing things that we're okay with as a society.
- But I think it's also it's a tricky one right? Because down the line, I mean, these are the kind of things that we do need to respond to, especially what do we do when there are truly bad developers and bad actors that are trying to misuse these kind of systems. So it's a good question. Hopefully, we as a society, have enough defense mechanism that we will gradually learn how to tackle these kind of problems.
- And maybe I'll take one last question. Carolyn or Caroline.
- 55:03
	Yeah. Hi, I really enjoyed the presentation. It was really interesting.
- But in the future, do you see? Like generative agents being accurate enough to like, predict, or like play, exactly what somebody will do or like. Think
- for like strategy games such as like chess and like, how do you think this will affect sports.
- 55:22
	Right. So sports are you thinking here more of like, literally like the I don't know, like soccer tennis like these kind of sports or sports, more like the mental sports like poker, and those kind of things.
- 55:35
	I think
- specific, like strategy based sports. So I I fence. So I was thinking more like stuff like that.
- 55:44
- so here suddenly. If it's strategic games. I do think these agents will also get better at those, and hopefully there will be an interesting co-pilot as people try to develop their games and so forth. I do think it's an open-ended question as to how they will actually be a part of this space, though
- there are actually people that are working in sort of this intersection of AI agents and games. So I do expect that we'll actually start to hear a lot of, you know, really interesting games that will sort of show in this space, right?
- Maybe just one, if it's quick one, Audrey, maybe I can answer your question, and then we can end the session.
- 56:41
- 57:27
- The hope is if the models of individuals are good enough. It will enable us to answer those questions. Right? So basically, imagine you have a policy, can you actually implement the policy in the small game world that I just showed you, and see how people might actually live under that policy. I think those are really fascinating questions. We have some ways to go before we can really be confident that this is working scientifically. But that's the hope. That's, I think, where this is headed.
- 58:07
	Okay, sounds good. Thank you so much.
- 58:09
- 58:38
	Thank you so much, June, for your time. It's always a pleasure, and your talk is always really fun. So so glad everyone got to enjoy it. Thank you again for your time. Everybody say goodbye to June, and thank you.
- 58:51
	See you later. See you later. Everyone.
- 58:55
	And students. Reflection sessions start at 2 10, so feel free to hop there, take a break, and then we'll see you there
- bye.