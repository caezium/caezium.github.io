---
title: "Video Conferencing, Web Conferencing, Webinars, Screen Sharing"
source: "https://stanford.zoom.us/rec/play/9jeyCdKRcyMpL6_WxLSuHVMMirZujtmLgDARDBxQw-a14rMAsm7BK0WTXIt8PkT24QkUAnJBoxTFvXCq.yWYlwqYZ3KOM2O7W?eagerLoadZvaPages=&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2Fvzh2w03e-cNERc8PotJd43Y8NlclvylTMfnAQAiJsMbpWQY_Q-fLn7UvjPsj-HtV.cEYVYOP03B12gbfy"
author:
  - "[[Zoom]]"
published:
created: 2025-06-20
description: "Zoom is the leader in modern enterprise video communications, with an easy, reliable cloud platform for video and audio conferencing, chat, and webinars across mobile, desktop, and room systems. Zoom Rooms is the original software-based conference room solution used around the world in board, conference, huddle, and training rooms, as well as executive offices and classrooms. Founded in 2011, Zoom helps businesses and organizations bring their teams together in a frictionless environment to get more done. Zoom is a publicly traded company headquartered in San Jose, CA."
tags:
  - "clippings"
---
## Summary
Peter Norvig, an \\"AI hipster,\\" discusses the evolution, current state, and future of AI. He begins by comparing AI's learning capabilities to simple organisms and highlights the key difference from traditional software: AI handles problems without definitive answers and learns by being shown rather than told. He emphasizes the profound impact of written language on AI development, noting the unexpected power of simply \"dumping text\" into models for self-learning through word prediction tasks.

Norvig explains that large language models (LLMs) like ChatGPT, while sometimes dismissed as \\"stochastic parrots,\\" are much more sophisticated. He argues they generalize, form concepts, employ selective attention, and reason, going beyond mere echoing. He delves into how AI represents the world by generalizing from compressed information (written text) into neural networks, enabling it to answer questions and even write programs. He clarifies GPT as both \\"Generative Pre-trained Transformer\\" (AI term) and \\"General Purpose Technology\\" (economist term), stressing AI's new ability to perform diverse, unforeseen tasks.

Looking to the future, Norvig discusses the rapid pace of AI advancement, cautioning about the societal impact, particularly job displacement, and the need for ethical considerations and societal safety nets. He provides examples of AI's promise in fields like medicine, cybersecurity, agriculture, education, and mathematics, where it is already achieving breakthroughs previously thought impossible. He concludes by stressing the importance of defining clear objectives for AI, comparing it to the philosophical challenge of knowing \\"what you need\\" versus \\"what you want,\\" and advocating for safeguards like \\"undo buttons\\" and \"Are you sure?\" prompts in AI systems.


## Key Points
- **AI vs. Traditional Software**: AI tackles problems with no definitive answers and learns by being shown, not told.
- **Learning in Language Models**: AI learns by processing vast amounts of text, self-testing by predicting blanked-out words, which enables learning syntax, facts, and even arithmetic.
- **Beyond \\"Stochastic Parrots\\"**: Norvig argues that AI systems generalize, form concepts, exhibit selective attention, and reason, demonstrating capabilities beyond simple echoing.
- **GPT**: Stands for \\"Generative Pre-trained Transformer\\" (AI) and functions as a \\"General Purpose Technology\\" (economics), capable of diverse and unforeseen tasks.
- **Promise and Peril**: AI offers tremendous potential in fields like medicine, education, and science, but also poses risks like job displacement and unintended consequences, requiring careful societal management and ethical objective-setting.
- **Current Focus**: Norvig is actively involved in applying AI to education, particularly in developing personalized, mastery-based tutoring systems.
- **Classical AI Relevance**: Traditional AI techniques (e.g., search algorithms in AlphaGo) remain crucial when combined with modern deep learning for achieving breakthrough results.
- **Impact**: His most rewarding work has been contributing to Google Search, impacting billions of users globally.

---

https://stanford.zoom.us/rec/play/9jeyCdKRcyMpL6_WxLSuHVMMirZujtmLgDARDBxQw-a14rMAsm7BK0WTXIt8PkT24QkUAnJBoxTFvXCq.yWYlwqYZ3KOM2O7W?eagerLoadZvaPages=&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fstanford.zoom.us%2Frec%2Fshare%2Fvzh2w03e-cNERc8PotJd43Y8NlclvylTMfnAQAiJsMbpWQY_Q-fLn7UvjPsj-HtV.cEYVYOP03B12gbfy
# Original Content

[Accessibility Overview](https://stanford.zoom.us/en/accessibility)

<video src="https://ssrweb.zoom.us/replay02/2025/06/18/02FC2E57-960D-4C48-8622-347EF20C1185/GMT20250618-165720_Recording_2560x1440.mp4?response-content-type=video%2Fmp4&amp;response-cache-control=max-age%3D0%2Cs-maxage%3D86400&amp;data=ba89b7a4df6f0b14f6c49cce8fafe06ecf7a69d8d0c89f91def92d21f26953e0&amp;s001=yes&amp;cid=aw1&amp;fid=fXLUIQktaqfeOerwtzEGIuU2asaAbfeqUFRd0sknZ4G25DoVy4_SQYzbMSucdgPAHLY5O_FapuV8h4SK.YSWUm3b-bw4_7BvI&amp;s002=MHppK53_wmXr3iFFkemNG3ORawrQ2g_VVQcNTDe8j7TfIKJUm8xmsQSFxnqc7bYYmTBGGBWMMlLfoBMMWiXT_6lol2Tw.pEkIWJXrOJiBtZs2&amp;tid=v=2.0;clid=aw1;rid=WEB_2ec1f4c8dd8228685c56af5c8c500c46&amp;Policy=eyJTdGF0ZW1lbnQiOiBbeyJSZXNvdXJjZSI6Imh0dHBzOi8vc3Nyd2ViLnpvb20udXMvcmVwbGF5MDIvMjAyNS8wNi8xOC8wMkZDMkU1Ny05NjBELTRDNDgtODYyMi0zNDdFRjIwQzExODUvR01UMjAyNTA2MTgtMTY1NzIwX1JlY29yZGluZ18yNTYweDE0NDAubXA0P3Jlc3BvbnNlLWNvbnRlbnQtdHlwZT12aWRlbyUyRm1wNCZyZXNwb25zZS1jYWNoZS1jb250cm9sPW1heC1hZ2UlM0QwJTJDcy1tYXhhZ2UlM0Q4NjQwMCZkYXRhPWJhODliN2E0ZGY2ZjBiMTRmNmM0OWNjZThmYWZlMDZlY2Y3YTY5ZDhkMGM4OWY5MWRlZjkyZDIxZjI2OTUzZTAmczAwMT15ZXMmY2lkPWF3MSZmaWQ9ZlhMVUlRa3RhcWZlT2Vyd3R6RUdJdVUyYXNhQWJmZXFVRlJkMHNrblo0RzI1RG9WeTRfU1FZemJNU3VjZGdQQUhMWTVPX0ZhcHVWOGg0U0suWVNXVW0zYi1idzRfN0J2SSZzMDAyPU1IcHBLNTNfd21YcjNpRkZrZW1ORzNPUmF3clEyZ19WVlFjTlREZThqN1RmSUtKVW04eG1zUVNGeG5xYzdiWVltVEJHR0JXTU1sTGZvQk1NV2lYVF82bG9sMlR3LnBFa0lXSlhyT0ppQnRaczImdGlkPXY9Mi4wO2NsaWQ9YXcxO3JpZD1XRUJfMmVjMWY0YzhkZDgyMjg2ODVjNTZhZjVjOGM1MDBjNDYiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NTA0MTc3MDB9fX1dfQ__&amp;Signature=FwweSkhhUlZ1-7u8svTJYrNOH3N3sbcIvRfa2nmfs0iqKhUp41wsUyuzxHB19up9R7pLH0PsJo3g2lyU~XgXH8W3N8crTVRQmNLhzIpe8BFxJjuKz5b7Y~EXWkTZrzoORiUnL~RMaQE7f6nzVtVf-aIt8gdiOUT5Mb9E5yWcY~IfAK05ghJo3zBWrOK0mB0ibotWaeEaGMy6Rpw2shCXidx73qCcQiH7p-kqc3pIQcptY8BAhK4AmKy4ROVVE58FllD-H90R~9avqiyOq7IvLhktR6JTkd43SP-TA5pcPPz~MuvS38XJi~Qod3Cs7h8JP5UxbCKNxZbDilNQTHQ9oA__&amp;Key-Pair-Id=APKAJFHNSLHYCGFYQGIA"></video>

Field I've been in for a long time, uh, so, you know, I'm aâ€¦ I'm an AI hipster. I was doing it before it was cool.

00:00:05 / 00:47:33

## Audio Transcript

## Chat Messages

- 00:02
	Of the
- and let's go way back to the past. Let's go back 20 million years ago, and here are these little sea elegans worms. They're about a millimeter long, and we've mapped out their nervous systems. And they have, unless they're unusual. They have exactly 302 neurons. And we kind of know what it does.
- And these things they swim around, they observe their environment, they can go towards food. They can go away from predators and so on. And they can basically learn what makes them successful by applying this nervous system in the right way.
- So that's really interesting that that they can do that. They have that capability, even though they're so simple.
- Now.
- here's an organism that's even simpler sunflowers. They have no neurons, but they, too, can observe their environment and change their behavior in order to improve themselves right? So they face towards the sun. And when the sun moves, they move. They're not making a conscious decision, but just kind of the way they're built and the chemistry inside their cells kind of forces them to turn towards the sun.
- And so it's it's all observing the environment and interacting with it.
- Now, in the present.
- we have human brains, and they've evolved quite a bit from these smaller animals from millions of years ago, and they have about a hundred 1 billion neurons in our brains.
- Coincidentally, these large AI programs also have somewhere in the range of 100 billion parameters, and we call them neural nets. I wish we wouldn't do that, because yes, in some ways they're similar to brains. They're observing the environment, making decisions and and trying to improve themselves. But in other ways it's really completely different.
- Sorry. Roxy's in the background there somebody walked by the house.
- So what's different about AI software versus the regular kind of software that that we've always had.
- And to me, one of the key things is to look at what are the difficulties? What makes software hard and for regular software? The problem is complexity. If I want to write the software for a bank. There's like thousands of different regulations and taxes and fees. And I got to get everyone exactly right. But there is a correct answer down to the penny. And I can know when I have it right
- for most AI problems. It's just not like that. So an AI problem is here I show you this picture of an eye. Is it normal, or is it diseased? And there isn't a definitive answer. Even expert doctors might disagree on this. But yet we're asking AI systems to make these hard choices. And that's really different from the way we use software in the past.
- Then another thing is that we build these systems by showing them rather than telling them. So. Here's a picture of me with one of my 1st teachers, my mom. And she's showing me something. And on the right we have a picture of of how we do traditional software by telling it step by step, every single thing rather than having it be flexible and learn on its own. So that's what's different about AI.
- Now
- let's go back again into the past. About 5,000 years ago, humans developed writing. And that's really has made all the difference to me. This is the most amazing technology we've ever developed, far, far more amazing and useful than computers and electronics and cars and everything else. Because writing is what allows our civilization to advance from one generation to the next.
- And yeah, spoken language. That was pretty important, too, and that allowed us to build up a civilization and and go from just small tribes to having cities, and so on and cooperating with each other, but it's the written language that allows us to pass it down from one generation to the next and improve on it.
- And AI has taken advantage of that. So how do we take advantage of that? So
- you know I want to go back in time again to when I was your age, and I was in high school. And
- we had a computer class in my high school was actually was unusual at that time. Most high schools didn't, and we also had a class in linguistics, and that was unusual, and I took both those classes, and I said to my teachers, you know. It seems like there's something in common here between the way you talk to a computer and what's going on in linguistics and learning the rules of syntax, and so on. Could I put those 2 together?
- And at the time my teacher says, Yeah, that seems really interesting. We don't know enough to tell you how to do that. But good luck! And that's sort of what I spent the rest of my career doing, and I always thought
- as I was getting into this, that it's really interesting to figure out what the words on the page are when you're reading a book or reading a file, or whatever, and that there's something really interesting going on there. But I always thought that the harder part would be figuring out what's going on inside the head of the reader as you're looking at the words. So yeah, some information is in the words.
- but I thought more was going on inside the head, and that's what the hard part about doing AI would be.
- And then
- we wanted to transfer that to say, could we take a bunch of text and then put it into the head of the computer. And we thought, we're really going to have to tell it, the computer what to do step by step. It's not enough to just dump the text. In.
- Turns out I was mostly wrong, and that it is enough to just dump the text in. So there's far more of what's actually happening in the world
- gets encoded into the text than what we originally thought. And that's, I think, been the biggest surprise of the last 5 years.
- So how does AI work?
- And for these language models the way it works is just by pouring in a bunch of text and then having it, observe that text and improve itself. So how do you do that? Well, you want to give it tests, and then have it get them right or wrong.
- and you could have you know the way you guys are tested in school. You could have exams. Some teacher could make up the questions, but that's too hard and slow. It's hard work on the part of a teacher. So instead, what we do is we use the text itself to make up its own problems. And what we do is we feed in a text. But we blank out one word at a time
- and ask the computer to guess what that word is right. So we show it a sentence with a missing word and have it. Guess what that word is if it gets it right, we say, do more like that. If it gets it wrong, we say, modify yourself so that you're more likely to get it right next time, and that's all we do. And every single word is a potential text. And you just do that billions and billions and billions of of test problems. And it keeps getting better.
- So that doesn't seem like much. What can you do just by learning? By blanking out one word at a time? Well, it turns out you can learn a lot.
- so you can start learning the syntax of a language such as English, right? So by blanking out the A and then blanking out the, and you eventually learn that we use a between before a word that starts with a consonant sound, and we use, and before a noun that starts with a vowel sound, and we learn that part of syntax, and we can learn all the rest of the syntax as well.
- But it's more than that we can learn geography by by looking at the words there, and if you guess, is it to the east, or is it to the West? You get it wrong next time you're more likely to get it right.
- We can learn arithmetic. We can learn the conversion factor between kilometers and miles from this one example, you couldn't learn that. But after it sees thousands of examples, starts to figure out how that conversion factor works. And now multiplication and division works. So all that is done just by giving it tests of blanking out one word at a time and asking it to get the right answer.
- Now, once we have that we have what's called a language model, and things like Chat gpt, we call them language models, and that's come to have kind of a general meaning, but it actually has a very specific scientific meaning, and that language model
- is a probability distribution of what's the most probable. Next word given what you showed me so far, and that's all we mean by language model. But then we make the language model smarter by what we call adaptation.
- by going through and doing things like saying, well, we're going to give you a specific prompt that's going to make you do better. We're going to. Yes, we had you automatically learn from examples step by step. But we're also going to put some humans in the loop to help you learn and learn from their smart judgment, and so on, and so on. There's a bunch of a dozen or
- so strategies we use to make the system better. But most of it comes just from self-learning.
- Then we want the systems to be smarter than than just doing an answer. And
- one of the things we do is we teach it to be smarter in the way it responds. So if you just ask it, here's a question, what's the answer? Sometimes it gets a right, sometimes it gets it wrong if you, if you remind it. Well, think through. Sort of, you know. Sometimes you're asked on your test. Show your work when you're doing a math problem. If you remind these AI systems to show their work and work it out, then they do better
- you can allow them to use tools. Allow them to call programs or access external databases. You can have multiple AI systems communicate with each other and and maybe vote on on what result is best, and maybe even call in some humans for help when they need them. You can personalize it to to my needs or your needs, and you can specialize it.
- save you by the system.
- Just for medical condition.
- Let me see if I can let Roxy out, so she'll calm down.
- Okay, we're back now
- one of my colleagues, Emily Bender and and her co-authors wrote this paper that says, Well, maybe we shouldn't be so impressed by these language models. Maybe they're just what she called stochastic parrots, which says all they're doing is just echoing back what they learned. Now, I don't really like that phrase. For one thing.
- I think this is unnecessarily mean to parrots. I think parrots are really cool and really smart. So calling someone a parrot. That shouldn't be an insult. But the other is, I think it's it's not really getting at what's going on here.
- And to emphasize that, let's try this little exercise. You can all do this on your own so complete this poem.
- Roses are red, violets are blue.
- I'm a stochastic parrot, and so
- blank blank. And if you got, are you? Then maybe you are right. So maybe what we're doing a lot of times is just completing what obviously comes next, and maybe that's not so different than what the computers are doing. Now, if
- if the computer models were just this language model just saying, given a sequence of words. What's the most probable next word? Then I would agree that that's not very interesting, that's a stochastic parrot, or whatever you want to call it. But they're doing much more than that.
- what was the previous word, but pay attention to the important stuff and forget the unimportant stuff.
- They can consider different alternatives and weigh them against each other, and and reason say, well, 1st I had this idea, but then I found some evidence against it, and I went with another idea. So to me they're doing much more than just echoing. I think that's important.
- Okay.
- Now, another thing that I think is important is the way they represent the world and come to make good generalizations. So so this schematic chart says, we start with a world in which lots of complicated stuff is happening.
- and our computers don't have complete access to that whole world. Most of what we have is compressed down into what's written.
- and that good step is important, because authors decided what was important, and wrote that down and didn't write down the important stuff. So we've gained a lot by saying we're going to try to learn what other people thought were important, what teachers thought we should know.
- And then we encode it further into this neural network inside the computer. And
- it can't memorize everything in all those books, so instead of memorizing, it has to generalize, and in order to generalize, it's got to say, well, what's important about what I read, and let's represent that rather than try to memorize every single word. Let's get the gist of what was important, and that's what's encoded into our networks, and then we ask it a question, and it comes up with an answer.
- and it's got to do some reasoning in between.
- And sometimes it does that by coming up with an answer. That's an English paragraph. And in order to do that, it's got to figure out what's important. Sometimes it does that with a more formal language. So you can ask it to solve a programming problem. And it comes up, writes a program, and then it can run it. And that's really useful. By using these other languages like programming languages.
- you can actually run the program and see if it's right or wrong.
- So it's using these external tools. And I think that's important.
- No.
- So you're probably all familiar with Chat Gpt, you wonder what does just Gpt mean? And in AI it means generative free train transformer. So generative means it can come up with something new. It can invent a new paragraph rather than what we, the alternative to that is called discriminative. So, like an email, spam filter is
- discriminative. It can say, this is spam. It goes into the spam inbox. This is good. It goes into your inbox, but it couldn't generate a spam message. Pre trained means. We give it all this text ahead of time and train it, and transformer means it.
- It transforms the input into an output. But I think it's also interesting that economists
- have before Chat Gpt. They had an abbreviation Gpt which they call general purpose technology. And for them it's things like electricity is a general purpose technology. It doesn't just help us do one thing. It helps do lots and lots of things. And that's, I think what's really interesting about these systems is that they do lots of different things. And that's new.
- We used to write software to do just one thing at a time. And now we have software that can do lots of things, including things that the authors of the software never thought of. So that's a big change.
- In 1958, Herb Simons, one of the founders of the field of AI Nobel Prize winner. It was great excitement for me to be able to to meet him earlier before he died in 1958, he said, well, we're just starting to get these AI systems. And he said, they're now in the world machines that think.
- And we sort of changed what we thought computers were good for, because back in 1958, we thought they were just like calculators. Right? You give them some numbers. And something comes out. And he started to deal with programs that could solve logic problems and so on. And that was new.
- And now we have Sam Altman saying, AI will be a reality in 5 years. People argue about that. When exactly, is that coming? What exactly does it mean? I would rather not have a term like General AI. I would rather say, well, AI is going to be good at some things, and not so good at other things, and some things we shouldn't even bother trying to do with it. So it's not like there's 1
- second when you achieve this. But rather, I say, it's going to become more and more useful for lots of different things, and we better be careful about how we apply it in just the right way.
- So, as Spiderman says, with great power comes great responsibility. So we want to use this right.
- And in all technologies we have to worry about unintended consequences.
- So automobiles was a great invention. Right? We can distribute food and and everything else to people in a way that we never could before made everybody's standard of living better, but also has a lot of bad consequences, like air pollution and traffic and traffic injuries, and so on.
- And then there's also intended destruction. So the airplane was a great invention that opened up the world, but it also allowed for the possibility of bombing cities in a way that was far more destructive than before. The invention of airplanes.
- This was an interesting article from foreign policy which looked at AI and looked at the promise and the peril. And I think that's a good way to look at it. We have to say
- there's awesome things we can do with this technology. But we also have to worry about the risk and deal with that.
- So here's an example of inventing a plant that has a disease resistant protein in it.
- We couldn't do that with just what we knew about chemistry. But with AI systems we're able to understand these things in a way we couldn't before. And we're inventing all these new types of chemistry and so on. And I'm just going through a few examples that came up just like in the last week. Here's a company that talked about healthcare for aging people. There wasn't a nice advance in cyber security.
- And yeah, AI can be used by the bad guys in cybersecurity as well as by the good guys. I think I'm now convinced that it's going to be more useful for the good guys. So I'm optimistic here. I've seen half a dozen companies that are talking about. Well, we're going to fly drones to do agriculture better analyzing them with AI,
- a bunch of companies doing education, saying, we can communicate with students better. And we can help the teachers do a better job by concentrating on what what they can do best and have the AI do what it can do best.
- Now, this was not from the last month. This is like a year ago. But I think this is really interesting, and this field continues to move right? So using AI for mathematics, and there's a part of mathematics that just wrote. You follow out the formulas. But there's a part that's creative and real. Mathematicians
- have to come up with something brand new, and it used to be that they were on their own to do that. But now it seems like AI is really helping
- and here's an example of Deepmind's alpha proof, which says, I'm going to take an informal problem
- the way you know, a mathematician states it kind of in a combination of English and mathematical formulas that are Gonna make it into a formal problem and use the AI to solve it.
- And Timothy Gowers, one of the top mathematicians, says the fact that the program came up with a non-obvious construction is very impressive. Well, beyond what I thought was possible. So in the last year this has all changed. This has all become possible.
- Openai has done this. Terrence Tao, another famous mathematician, said the same kind of things that it's now doing, stuff that I never thought was possible before. And here, in the middle, he says, the experience seems roughly on a par with trying to devise trying to advise a mediocre but not completely incompetent graduate student.
- and he says, this is brand new. A year before I would have said, it's completely incompetent. Now it's kind of at the level of a graduate student. And so we're making these fantastic advances very, very quickly. And I think that's important for the world to understand how fast this is moving.
- So just a summary of where we've been in software in the last 50 years started out. We communicated with computers and assembly language because that was efficient for them. Then we use languages like Python, because that was more efficient for our human programmers. And now
- we can talk to them in English, and they can come up with answers. So that's changing how we communicate with computers.
- When I started in the 19 eighties, AI was all about defining algorithms.
- Then around the 2 thousands, we had this era of big data where we said, if you want to make the machine better, it's probably better to give it better data rather than try to come up with a better algorithm.
- And today, I think we're in this field where it's really important is the objectives to decide. We got plenty of good algorithms, plenty of good data. But we want to tell our programs. What is it that you should be doing. What is it that I want or I need, and how machines are really good at optimizing? But you got to tell them what to optimize.
- And so maybe we need more philosophers rather than programmers.
- And here's a noted philosopher, Professor Mick Jagger, who said, you can't always get what you want.
- But you get what you need. But I think he got it backwards because we built this amazing Internet system to give you what you want.
- And every time you click on something that's more feedback that you get more of that, and so do all your friends right. So I waste some time playing a game. And then I said, Man, I wish I had that time back. I wish I hadn't wasted that time, but it's too late for me, and it's also too late for you, because if you're connected to my network, then it's going to be more recommendations for you to do more of that.
- So we're really good at satisfying what you want, but not good at satisfying what you need. So all these kind of global things that are really important. We don't have a feedback mechanism to make them work on the Internet. And I think that's something we need. We need to do a better job of saying, what is it that's really important to us? And let's have our systems work on that rather than work on the stuff. That's not that important to us
- and getting this right of saying what's important. That's really hard now. 200 years ago, Judge Blackstone said. It's better that 10 guilty persons escape than that one innocent suffer right? So you're not going to get every court case right.
- And he's saying, Here's how you should make the trade off. I'm not sure if he was literal. It's like 10 is better. But 11. No, that would be worse. I don't think he's trying to be quite that qualitative, but he's saying we should kind of err in this direction, and we have to build our society based on those kinds of preferences. For which way do we want to go.
- and we've had hundreds of years of examples in our myths and stories about how this is hard saying what you want. So here's King Midas. And he was asked what he want, and he said, I want everything I touched to turn to gold. But then he realized he made a mistake when he touched his daughter, and she turned to gold.
- And you know the genie, you always get 3 wishes, and sometimes you get it wrong. You wish you could get that back, and we have warnings to try to get that right. But there is technology where we could do a better job right? So King Midas should have said everything I touch. I want to turn to gold, but I also want an undo button.
- and if something is important I want a little pop up that says, Are you sure? Right? So we have technologies to do a better job on this, and we've got to take advantage of those. And if we can do that, then I think the promise will outweigh the peril.
- so let's stop there and open it up for questions.
- and I'll let Roxy back in through the door.
- 27:24
	Brilliant. Thank you so much, Professor Norbig. At this time we can open up for questions. If you'd prefer to put your question into the chat and have it be read. We can do that, or you can feel free to come off mute and ask questions.
- 27:41
	Hey, Professor Norvig?
- 27:43
	Bye.
- 27:44
	Hey? I was wondering if you could talk to us a little bit about your work currently, or in the past, or any any of your work that you've done.
- 27:53
	Yeah. So I'll talk about now, because that's most fun. So I'm really interested in applying AI to education, right? So we've learned some things about education. And and one of the things we've learned is that the most effective way is kind of direct tutoring rather than lecturing. Right? So if I lecture to a big classroom of 100 students.
- I'm probably going too fast for 50 of them, and too slow for the other 50, and maybe a big part of what I'm talking about is not interesting to them, but they really want to hear about something else.
- If you have a 1-on-one tutor, then you can get that. And the other thing we do wrong in our school system is, we say, you know, we're going to teach this subject for a week, and then we're going to have a test, and if you get a C on the test well, too bad! Next week we're going to do something harder, and you're probably going to get farther behind.
- What we really should have is mastery learning where we say you keep doing it until you get it, and then we move on to the next thing, and then you'll be more successful.
- Right? So we know these things right? Educators have known these for decades that this is a better way to do it. But we've always said, Well, we can't afford that right. We can only afford one teacher for every 30 students or whatever. So sorry.
- But now maybe we have this technology to say, here's something where we could get this individual attention, and we could have every learner go at their own speed until they really understand it. With the help of these AI models. And the question is.
- Yeah, that seems right. And that seems like, you know, someday in the future that will work really well. But what can we do right now when these systems are flawed? How can we take a flawed system that's going to make a lot of mistakes and still have it be useful to these students. So so that's kind of what I'm focusing on right now.
- 29:52
	Okay, got it. Thank you.
- 29:56
	And next up I saw Teresa raise their hand.
- 30:00
	I appreciate it.
- Hi, Dr. Novik, I think, since large language models learn from human knowledge and reasoning, don't these, like human limitations, also restrict the models like, can we ever build models to go beyond human thinking?
- 30:15
	Yeah, so that's a great question. I think you're mostly right. So
- I think they are. There is a real limitation based on human thinking. Now.
- can it go beyond that? Well, yeah, in a couple of ways. So one is, it could be much better at memorizing everything that it reads. Second, it could work much faster than humans work.
- But I think you are mostly right. And to me that's really an encouraging thing rather than a discouraging. And here's why, right? Because there's some people right now that are worried about this super intelligence explosion of saying, you know, AI systems will get smarter, and then they'll build another AI system that's smarter still, and it will build a smarter system, and soon we'll be left behind, and we'll just be like
- insects to these super intelligent AI systems. And I don't think that's true, for just the reason you say that I think they're they're partially limited by building on what we have.
- On the other hand, I think they can go beyond it right. And we are seeing things like, you know. So I mentioned like the invention of new proteins. Right? So it used to be that as a biology student you could get a Phd. For describing how one protein folds up in shape as this long chain of proteins.
- And now an AI program just said, well, I figured out the answer for for every single protein that exists.
- And so it's being kind of as creative as a Phd student. And it's doing it much, much, much faster. And so, on the one hand, that's just kind of following out kind of automatically what could be done. On the other hand, that makes a big difference. And I think we're going to see, you know, inventions of new cures for disease, and so on, be greatly accelerated because of this kinds of capabilities.
- Okay, who's who's next? Brooklyn?
- 32:24
	Next we have Suman.
- 32:26
	Hi, Professor Norvig. So earlier you mentioned that you're not a fan of the term neural networks because of the differences between AI and the human brain. But my question is like at the end of the day. Doesn't the brain ultimately function through like a series of chemical and electrical reactions, and even emotions, like as complex as they may seem.
- are like ultimately traced back to like biochemical processes, and like, when it ultimately comes back to like original thought on our idea is also shaped by like what we already know. So like, beyond the fact that humans are biologically alive, like, what do you think truly differentiates us from AI.
- 33:01
	Yeah, so that's a great question. So I agree that you should think of humans and other animals as machines. They're just biological machines rather than electronic circuit machines.
- But I guess what I was trying to say is.
- you know, when we when we build these AI models, they're somewhat like a human brain in that. They're saying it's not like a computer where you're just
- storing one. You know, the variable variable X is a value 100. And it's stored in one little box. Rather there. There are all these connections between different parts. And and to that extent it's similar to to a human brain. But
- beyond that, it's like, we're not trying to duplicate how the human brain works. We're trying to build the most efficient computer. And you know, we haven't had success by saying, I want to make an exact duplicate of the neurons in the human brain. So if you're not trying to duplicate them, I think, taking their name is a little misleading. So that's all I meant by that.
- 34:18
	And next we'll have Kelly.
- 34:22
	Hi, I'm from New Jersey, and I have a question, can AI like open any industries or jobs in the future? And if so, which ones.
- 34:33
	Yeah, so and that's been a big controversy, too. Of you know what new jobs are coming and what old jobs are are going to be displaced. I think,
- that's that's something we should definitely be worried about, because it's always been the case that technology has changed the distribution of jobs. Right? So
- there was a time 200 years ago when most people in America were farmers.
- And now a very small percentage are farmers, because the technology is so much more powerful. We don't need that many. And that was overall really good food got cheaper and more plentiful and more varied and more healthy, and there wasn't that bad effect because it happened slowly.
- Right? So you know, you might have someone who said, Well, my parents and my grandparents were farmers, and I'm a farmer, and I respect that tradition, but it looks like my kids. They've chosen to go to college and go off and live in the big city, and they're not going to be farmers. So the change happens over generations. But if the change is happening now over years or months.
- you know, the 1st time you say, well, I had a job, and then it got disrupted by AI, and I trained to have another job. And you say, Oh, that's okay. But if it keeps happening every year.
- going to start to get annoyed by that and feeling bad, and there may be some pushback and revolutions against that. So we're going to have to be careful to say, Yeah, there's going to be a lot of wealth created. There's going to be a lot of new possibilities, and and people will work doing that.
- But we also have to worry about this disruption, and people don't like change to go too fast, and the pace of change of AI just doesn't seem to match the pace of change that people are comfortable with.
- So we're going to, I think, have to have some societal ways to make that transition easier. And people have talked about ideas
- like universal basic income. Right? So if you're out of a job, for whatever reason, maybe everybody gets a level where they're comfortable until they can find something else to get them going again. So some kind of safety net because we've had job security as a safety net. That's already been
- partially eroded due to technology. Right? So if you think back 2030 years ago it was more common for someone to come out of college
- 38:01
	Thank you, and next we'll go to Luna.
- 38:04
	Hello! Hi, Professor Norvig! I'm Luna from Palo Alto, California, and I was wondering what books besides your own. Have you have influenced your thinking about AI, the most either like technically or philosophically.
- 38:17
	Yeah, I guess at least recently, I'm kind of negative on books, maybe even my own, because it just takes too long to publish a book, right? So you know, the the cycle for publishing a book is a year or multiple years.
- 38:55
	Great, and next we will go to Anandita.
- 38:58
	Yeah, Hi, Professor Norvik, I had 2 questions. So the 1st one is, how do you evaluate the importance of understanding classical AI, like planning and constraint, satisfaction in an era where many people just jump straight to deep learning.
- 39:15
	Yeah, that's a great question. I think that part is still important. And
- and I think we'll we'll see that going forward, and we already are, seeing that to an extent. Now, right? So you look at you know what are the big advances of AI? Well, one of the milestones that happened a couple of years ago was Alphago beating the world. Go champion right? And so part of. And that was a big surprise, right? So it happened in chess back in the nineties. And people said, Well, it's gonna happen eventually and go. But it's going to be decades more. And then
- Deepmind was able to do it in a couple of years, and part of that was was due to deep learning. So that was really important, that they needed a good representation of what's going on in the board. But then part of that was traditional. AI of saying, we're going to do a search over the possible
- moves that I can make, and then the moves you make, and then the moves I make. And they they use this approach called Monte Carlo rollout trees. And so that was important, right? And if if the team had only known deep learning
- they could have built a good system that definitely could have clobbered me, but it wouldn't have built it wouldn't have beat the world champion. And so, knowing how to put these components together, knowing what the components are. I think that's going to continue to be really important.
- 40:48
	Yeah, thank you. That was really insightful. So my second question.
- 40:52
	Sorry, Anandita. We we have a lot of questions.
- And so yeah.
- pause at one. But we actually only have time. If it's okay with you, Peter Norvik, for one more question to answer from those who have been also waiting patiently in the chat. So this 1st question is from Aran Sagi from Austin. What's your favorite piece of work that you've done.
- 41:19
	I guess it's it's being involved with Google and running the search team from for for about 5 years or so. Then I've had other jobs at Google but you know I was an academic for a while, and then I got into industry because I wanted to have a more effect on people.
- and I was at some small companies where we had a small number of customers, and that was great, and it was exciting to build stuff and say, You know, this is mine, it's out there. But at Google it went from having a small number of customers to having billions of customers and saying, You know, I really feel like I have an impact on the world. It's not just that I wrote a paper that a bunch of academics
- can read, but that billions of people out there can use what I helped along with the rest of the team to build and have an impact and try to make their lives better. So that was most rewarding for me.
- 42:22
	Yeah, thank, you.
- 42:23
	Thank you so much, Peter.
- 42:51
- 43:14
	Sounds great. Thank you again. Thank you so much for your time. Let's go ahead and get a round of applause to Professor Peter Norvig for spending such a great deal of time with us this morning. That was fantastic, great! And we're looking forward to seeing you again in the near future. Thank you so much.
- Thank you. I'm going to hand it over to Fatima. Who's going to give a couple of announcements. Here we are getting ready for a break before we get into some more content for our program today. So right before we go to break.
- Alright! Thank you.
- 44:07
	Thank you.
- and then I'll drop something in the chat.
- Here we go.
- Okay, here we are.
- Alright. So you all should be able to see the student assignments. And I'm going to drop in the chat
- some important links which include the Zoom link for your Group Project lecture, which is coming up.
- and then also
- the Handbook. So I think we've mentioned this in the emails prior. But the Handbook is essentially going to be like
- what you're referencing to go to the zoom links for each of the sessions. It's a live document, and so there might be changes that are changes that are made. And so we ask you to frequent, and in return to it
- we also wanted to drop in the chat, the Google classroom, if folks could please at this moment just like click into it, make sure you accepted the Google classroom. Invite. If you haven't received it. Please speak up now. Also the group me once you click it, you should be able to access it, and if you can't.
- then please. You can. You can reach out to rhythm, or you can stay over a little bit. And if you've already been in contact with our team regarding any technical issues around that. We will be in communication with you shortly. But yeah.
- if there are any questions please feel free to stay over. But aside from that, that was my announcement. Just a lot of logistical stuff. You all thank you for for staying and great questions.
- 46:21
	Thank you so much, Fatima, for putting this together for us to view, and our group lectures will begin in about 10 min. So you have a 10 min break right now and then the links that were put into the chat. You will find your team, and then you'll use that zoom link to meet with your your graduate mentors.
- so we'll go ahead and leave this up here. And then once we get closer to
- 11 o'clock, go ahead and click on your zoom link and join your team.
- 47:02
	Awesome. Well, we hope that you all have a good break. And yeah, we'll be here if you have any questions.
- 47:26
	Oh, yeah, I have a quick question. I emailed Miriam, a few days ago to like, ask if.